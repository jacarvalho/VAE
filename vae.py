from __future__ import print_function
import os
import argparse
import yaml
import pickle
import numpy as np
import torch
import torch.utils.data
from torch.utils.data import DataLoader
from torch import nn, optim
from torch.nn import functional as F
from torchvision import datasets, transforms
from torchvision.utils import save_image
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
plt.style.use('seaborn-darkgrid')


class DataHolder:

    def __init__(self, dataset):
        self.dataset = dataset
        self.train_holder = None
        self.test_holder = None
        self.height = None
        self.width = None

    def load_datasets(self, batch_size, device):
        # Load dataset
        dataset = None
        if self.dataset == 'mnist':
            dataset = datasets.MNIST

        kwargs = {'num_workers': 1, 'pin_memory': True} if device == 'cuda' else {}
        self.train_holder = DataLoader(
            dataset(root='./data', train=True, download=True, transform=transforms.ToTensor()),
            batch_size=batch_size, shuffle=True, **kwargs)
        self.test_holder = DataLoader(
            dataset(root='./data', train=False, download=True, transform=transforms.ToTensor()),
            batch_size=batch_size, shuffle=True, **kwargs)

        _, self.height, self.width = self.train_holder.dataset.data.shape


class Encoder(nn.Module):
    def __init__(self, input_dims, latent_dim):
        super(Encoder, self).__init__()
        self.input_dim = np.prod(input_dims).item()
        self.latent_dim = latent_dim
        self.fc1 = nn.Linear(self.input_dim, 400)
        self.fc2 = nn.Linear(400, 200)
        self.fc31 = nn.Linear(200, self.latent_dim)
        self.fc32 = nn.Linear(200, self.latent_dim)

    def forward(self, x):
        h = F.relu(self.fc1(x))
        h = F.relu(self.fc2(h))
        mu_z = self.fc31(h)
        log_sigma_z = self.fc32(h)
        return mu_z, log_sigma_z


class Decoder(nn.Module):
    def __init__(self, latent_dim, output_dims):
        super(Decoder, self).__init__()
        self.latent_dim = latent_dim
        self.output_dim = np.prod(output_dims).item()
        self.fc1 = nn.Linear(self.latent_dim, 200)
        self.fc2 = nn.Linear(200, 400)
        self.fc3 = nn.Linear(400, self.output_dim)

    def forward(self, z):
        h = F.relu(self.fc1(z))
        h = F.relu(self.fc2(h))
        mu_x = torch.sigmoid(self.fc3(h))
        return mu_x


class VAENetwork(nn.Module):
    def __init__(self, encoder, decoder):
        super(VAENetwork, self).__init__()
        self.encoder = encoder
        self.decoder = decoder
        self.latent_dim = self.encoder.latent_dim

    def forward(self, x):
        mu_z, log_sigma_z = self.encoder(x.view(-1, self.encoder.input_dim))
        z = self.reparametrize(mu_z, log_sigma_z)
        x_pred = self.decoder(z)
        return x_pred, mu_z, log_sigma_z

    @staticmethod
    def reparametrize(mu_z, log_sigma_z):
        eps = torch.randn_like(log_sigma_z, requires_grad=False)  # Do not propagate through this node
        return mu_z + eps * torch.exp(0.5*log_sigma_z)


class VAE:

    def __init__(self, vae_network, data_holder, optimizer=None, device=torch.device('cpu'),
                 results_dir=None):
        self.vae_network = vae_network
        self.device = device
        self.data_holder = data_holder
        self.optimizer = optimizer
        self.epochs = None
        self.log_interval = None
        self.results_dir = results_dir

    def train(self, epochs, log_interval, cb_func=None):
        """
        Trains the VAE for the given epochs. Each epoch is equivalent to one pass through the whole dataset.
        """
        self.epochs = epochs
        self.log_interval = log_interval
        for epoch in range(1, epochs + 1):
            train_loss = self.train_epoch(epoch)
            test_loss = self.test_epoch(epoch)
            if cb_func:
                cb_func(epoch, train_loss, test_loss)
            # Generate a new image
            self.generate(epoch)

    def generate(self, epoch):
        with torch.no_grad():
            z_batch = torch.randn(64, self.vae_network.latent_dim).to(self.device)
            img_sample = self.vae_network.decoder(z_batch)
            save_image(img_sample.view(64, 1, self.data_holder.height, self.data_holder.width),
                       os.path.join(self.results_dir, 'sample' + str(epoch) + '.png'), nrow=8)

    def loss_func(self, x, x_pred, mu_z, log_sigma_z):
        """
        VAE loss function = kl + reconstruct
            kl: KL between multivariate gaussian and standard multivariate gaussian.
            reconstruct: reconstruction the image generated by the decoder and the original one.
        """
        kl = 0.5 * torch.sum(torch.exp(log_sigma_z) + torch.pow(mu_z, 2) - 1 - log_sigma_z)
        reconstruct = F.binary_cross_entropy(x_pred, x.view(-1, self.data_holder.height * self.data_holder.width),
                                             reduction='sum')
        return reconstruct + kl

    def print_loss_info(self, epoch, loss, n_data, dataset_info='train'):
        print("===> Epoch: {}/{}, Avg {} Loss: {:.3f}".format(
            epoch, self.epochs, 'Train' if dataset_info == 'train' else 'Test', loss / n_data))

    def train_epoch(self, epoch):
        self.vae_network.train()  # Set training mode in pytorch. This is not always necessary.
        train_loss = 0
        for batch_id, (x_batch, _) in enumerate(self.data_holder.train_holder):
            x_batch = x_batch.to(self.device)
            x_pred_batch, mu_z_batch, log_sigma_z_batch = self.vae_network(x_batch)

            # Compute loss and backpropagate gradients
            loss = self.loss_func(x_batch, x_pred_batch, mu_z_batch, log_sigma_z_batch)
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

            train_loss += loss.item()
            if batch_id % self.log_interval == 0:
                print("Train epoch: {:3d}/{:<3d} [{:7d}/{:<7d} ({:2.0f}%)]\tAvg Loss: {:.3f}".format(
                    epoch, self.epochs, batch_id * len(x_batch), len(self.data_holder.train_holder.dataset),
                    100. * batch_id / len(self.data_holder.train_holder), loss.item() / len(x_batch)
                ))

        self.print_loss_info(epoch, train_loss, len(self.data_holder.train_holder.dataset), dataset_info='train')
        return train_loss / len(self.data_holder.train_holder.dataset)

    def test_epoch(self, epoch):
        self.vae_network.eval()  # Set evaluation mode in pytorch. This is not always necessary.
        test_loss = 0
        with torch.no_grad():
            for batch_id, (x_batch, _) in enumerate(self.data_holder.test_holder):
                x_batch = x_batch.to(self.device)
                x_pred_batch, mu_z_batch, log_sigma_z_batch = self.vae_network(x_batch)
                loss = self.loss_func(x_batch, x_pred_batch, mu_z_batch, log_sigma_z_batch)
                test_loss += loss.item()
            # Compare real and generated
            self.compare(epoch)
            # Latent space projection into 2D
        self.latent_projection(epoch)
        self.print_loss_info(epoch, test_loss, len(self.data_holder.test_holder.dataset), dataset_info='test')
        return test_loss / len(self.data_holder.test_holder.dataset)

    def compare(self, epoch):
        # Compare images from the test set with generated ones.
        x_batch = next(iter(self.data_holder.test_holder))[0]
        x_batch = x_batch.to(self.device)
        x_pred_batch, _, _ = self.vae_network(x_batch)
        n = min(x_batch.size(0), 8)
        comparison = torch.cat((x_batch[:n],
                                x_pred_batch.view(self.data_holder.test_holder.batch_size, 1,
                                                  self.data_holder.height, self.data_holder.width)[:n]))
        save_image(comparison.cpu(), os.path.join(self.results_dir, 'recon' + str(epoch) + '.png'), nrow=n)

    def latent_projection(self, epoch, n_points_max=1000):
        # Plot the 2D projection of the latent space mean
        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(4, 4))
        with torch.no_grad():
            y_batch = np.empty(1)
            z_batch = np.empty((1, self.vae_network.encoder.latent_dim))
            n_points = 0
            for x_b, y_b in self.data_holder.test_holder:
                x_b = x_b.to(self.device)
                mu_z, _ = self.vae_network.encoder(x_b.view(-1, self.vae_network.encoder.input_dim))
                z_b = mu_z.cpu()
                y_batch = np.append(y_batch, y_b, axis=0)
                z_batch = np.append(z_batch, z_b, axis=0)
                n_points += x_b.size()[0]
                if n_points >= n_points_max:
                    break
            # Project and plot
            tsne = TSNE(n_components=2)
            z_batch_pc = tsne.fit_transform(z_batch)
            cmap = plt.get_cmap('hsv', np.max(y_batch) - np.min(y_batch) + 1)
            sctr = ax.scatter(z_batch_pc[:, 0], z_batch_pc[:, 1], c=y_batch, alpha=0.5, cmap=cmap)
            plt.colorbar(sctr, ax=ax, format='%d')
            ax.set_xlabel('z1')
            ax.set_ylabel('z2')
            ax.grid(True)
            fig.tight_layout()
            fig.savefig(os.path.join(self.results_dir, 'latent_space_2d' + str(epoch) + '.svg'), format='svg')
            plt.close(fig)


class LossHolder:

    def __init__(self, results_dir):
        self.epoch = []
        self.train_loss = []
        self.test_loss = []
        self.results_dir = results_dir

    def __call__(self, epoch, train_loss, test_loss):
        self.epoch.append(epoch)
        self.train_loss.append(train_loss)
        self.test_loss.append(test_loss)

    def save_loss(self):
        d = {'epoch': self.epoch, 'train_loss': self.train_loss, 'test_loss': self.test_loss}
        with open("loss.pkl", "wb") as f:
            pickle.dump(d, f)

    def plot_loss(self):
        fig, ax = plt.subplots(nrows=1, ncols=1)
        ax.plot(self.epoch, self.train_loss, label='train')
        ax.plot(self.epoch, self.test_loss, label='test')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Nats')
        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.25), ncol=2, frameon=False)
        ax.grid(True)
        ticks = [x for x in self.epoch if x % 10 == 0]
        ax.set_xticks(ticks)
        ax.set_xticklabels(ticks)
        fig.tight_layout()
        fig.savefig(os.path.join(self.results_dir, 'train_test_loss.svg'), format='svg')
        plt.close(fig)


def main():
    # Setup
    parser = argparse.ArgumentParser(description='Variational Auto Encoder')
    parser.add_argument('--configs-file', type=str, default='configs.yaml',
                        help='path to configs file')
    args = parser.parse_args()

    cfgs = yaml.safe_load(open(args.configs_file, 'r'))

    torch.manual_seed(cfgs['seed'])
    cfgs['device'] = torch.device('cuda' if cfgs['use_cuda'] and torch.cuda.is_available() else 'cpu')

    if not os.path.isdir(cfgs['results_dir']):
        os.makedirs(cfgs['results_dir'])

    # Load the data
    data_holder = DataHolder(cfgs['dataset'])
    data_holder.load_datasets(cfgs['batch_size'], cfgs['device'].type)

    # Train the Variational Auto Encoder
    encoder = Encoder([data_holder.height, data_holder.width], cfgs['latent_dim'])
    decoder = Decoder(cfgs['latent_dim'], [data_holder.height, data_holder.width])
    vae_network = VAENetwork(encoder, decoder).to(cfgs['device'])

    vae = VAE(vae_network, data_holder, optimizer=optim.Adam(vae_network.parameters(), lr=cfgs['lr']),
              device=cfgs['device'], results_dir=cfgs['results_dir'])
    loss_holder = LossHolder(results_dir=cfgs['results_dir'])
    vae.train(cfgs['epochs'], cfgs['log_interval'], cb_func=loss_holder)
    loss_holder.plot_loss()


if __name__ == '__main__':
    main()
